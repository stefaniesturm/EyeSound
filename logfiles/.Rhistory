} else if (test[iRow, "condition"] == "TesPasConLS2") {
test[iRow, "agency"] <- 0
test[iRow, "LS"] <- 2
test[iRow, "congruency"] <- 1
} else if (test[iRow, "condition"] == "TesPasConLS3") {
test[iRow, "agency"] <- 0
test[iRow, "LS"] <- 3
test[iRow, "congruency"] <- 1
} else if (test[iRow, "condition"] == "TesActIncLS1") {
test[iRow, "agency"] <- 1
test[iRow, "LS"] <- 1
test[iRow, "congruency"] <- 0
} else if (test[iRow, "condition"] == "TesActIncLS2") {
test[iRow, "agency"] <- 1
test[iRow, "LS"] <- 2
test[iRow, "congruency"] <- 0
} else if (test[iRow, "condition"] == "TesActIncLS3") {
test[iRow, "agency"] <- 1
test[iRow, "LS"] <- 3
test[iRow, "congruency"] <- 0
} else if (test[iRow, "condition"] == "TesPasIncLS1") {
test[iRow, "agency"] <- 0
test[iRow, "LS"] <- 1
test[iRow, "congruency"] <- 0
} else if (test[iRow, "condition"] == "TesPasIncLS2") {
test[iRow, "agency"] <- 0
test[iRow, "LS"] <- 2
test[iRow, "congruency"] <- 0
} else if (test[iRow, "condition"] == "TesPasIncLS3") {
test[iRow, "agency"] <- 0
test[iRow, "LS"] <- 3
test[iRow, "congruency"] <- 0
}
}
# Drop unnecessary columns
keepers <- c("condition", "channel", "window", "mean", "subject", "agency", "LS", "congruency")
test <- test[keepers]
View(test)
for (iRow in 1:length(test$condition)) {
if (test[iRow, "condition"] == "TesActConLS1x") {
test[iRow, "agency"] <- 1
test[iRow, "LS"] <- 1
test[iRow, "congruency"] <- 1
} else if (test[iRow, "condition"] == "TesActConLS2x") {
test[iRow, "agency"] <- 1
test[iRow, "LS"] <- 2
test[iRow, "congruency"] <- 1
} else if (test[iRow, "condition"] == "TesActConLS3x") {
test[iRow, "agency"] <- 1
test[iRow, "LS"] <- 3
test[iRow, "congruency"] <- 1
} else if (test[iRow, "condition"] == "TesPasConLS1x") {
test[iRow, "agency"] <- 0
test[iRow, "LS"] <- 1
test[iRow, "congruency"] <- 1
} else if (test[iRow, "condition"] == "TesPasConLS2x") {
test[iRow, "agency"] <- 0
test[iRow, "LS"] <- 2
test[iRow, "congruency"] <- 1
} else if (test[iRow, "condition"] == "TesPasConLS3x") {
test[iRow, "agency"] <- 0
test[iRow, "LS"] <- 3
test[iRow, "congruency"] <- 1
} else if (test[iRow, "condition"] == "TesActIncLS1x") {
test[iRow, "agency"] <- 1
test[iRow, "LS"] <- 1
test[iRow, "congruency"] <- 0
} else if (test[iRow, "condition"] == "TesActIncLS2x") {
test[iRow, "agency"] <- 1
test[iRow, "LS"] <- 2
test[iRow, "congruency"] <- 0
} else if (test[iRow, "condition"] == "TesActIncLS3x") {
test[iRow, "agency"] <- 1
test[iRow, "LS"] <- 3
test[iRow, "congruency"] <- 0
} else if (test[iRow, "condition"] == "TesPasIncLS1x") {
test[iRow, "agency"] <- 0
test[iRow, "LS"] <- 1
test[iRow, "congruency"] <- 0
} else if (test[iRow, "condition"] == "TesPasIncLS2x") {
test[iRow, "agency"] <- 0
test[iRow, "LS"] <- 2
test[iRow, "congruency"] <- 0
} else if (test[iRow, "condition"] == "TesPasIncLS3x") {
test[iRow, "agency"] <- 0
test[iRow, "LS"] <- 3
test[iRow, "congruency"] <- 0
}
}
# Load data
test <- read.csv("~/Uni/EyeSound/analysis/means/test_recoded.txt", row.names=NULL, sep="")
# Rename the columns
names <- c("experiment", "condition", "channel", "window", "mean", "subject")
colnames(test) <- names
# Clean the content of the last column
test$subject = substr(test$subject,1,2)
# Rename time windows to component names
test$window[test$window == "+110..+140"] <- "N1"
test$window[test$window == "+210..+270"] <- "P2"
test$window[test$window == "+340..+400"] <- "P3"
test$window[test$window == "+230..+400"] <- "P2/3"
# Reshape the data
test[, "agency"] <-
NA
test[, "LS"] <-
NA
test[, "congruency"] <-
NA
for (iRow in 1:length(test$condition)) {
if (test[iRow, "condition"] == "TesActConLS1x") {
test[iRow, "agency"] <- 1
test[iRow, "LS"] <- 1
test[iRow, "congruency"] <- 1
} else if (test[iRow, "condition"] == "TesActConLS2x") {
test[iRow, "agency"] <- 1
test[iRow, "LS"] <- 2
test[iRow, "congruency"] <- 1
} else if (test[iRow, "condition"] == "TesActConLS3x") {
test[iRow, "agency"] <- 1
test[iRow, "LS"] <- 3
test[iRow, "congruency"] <- 1
} else if (test[iRow, "condition"] == "TesPasConLS1x") {
test[iRow, "agency"] <- 0
test[iRow, "LS"] <- 1
test[iRow, "congruency"] <- 1
} else if (test[iRow, "condition"] == "TesPasConLS2x") {
test[iRow, "agency"] <- 0
test[iRow, "LS"] <- 2
test[iRow, "congruency"] <- 1
} else if (test[iRow, "condition"] == "TesPasConLS3x") {
test[iRow, "agency"] <- 0
test[iRow, "LS"] <- 3
test[iRow, "congruency"] <- 1
} else if (test[iRow, "condition"] == "TesActIncLS1x") {
test[iRow, "agency"] <- 1
test[iRow, "LS"] <- 1
test[iRow, "congruency"] <- 0
} else if (test[iRow, "condition"] == "TesActIncLS2x") {
test[iRow, "agency"] <- 1
test[iRow, "LS"] <- 2
test[iRow, "congruency"] <- 0
} else if (test[iRow, "condition"] == "TesActIncLS3x") {
test[iRow, "agency"] <- 1
test[iRow, "LS"] <- 3
test[iRow, "congruency"] <- 0
} else if (test[iRow, "condition"] == "TesPasIncLS1x") {
test[iRow, "agency"] <- 0
test[iRow, "LS"] <- 1
test[iRow, "congruency"] <- 0
} else if (test[iRow, "condition"] == "TesPasIncLS2x") {
test[iRow, "agency"] <- 0
test[iRow, "LS"] <- 2
test[iRow, "congruency"] <- 0
} else if (test[iRow, "condition"] == "TesPasIncLS3x") {
test[iRow, "agency"] <- 0
test[iRow, "LS"] <- 3
test[iRow, "congruency"] <- 0
}
}
# Drop unnecessary columns
keepers <- c("condition", "channel", "window", "mean", "subject", "agency", "LS", "congruency")
test <- test[keepers]
View(test)
# Convert to appropriate data types
test$condition <- as.factor(test$condition)
test$channel <- as.factor(test$channel)
test$window <- as.factor(test$window)
test$subject <- as.factor(test$subject)
test$agency <- as.factor(test$agency)
test$LS <- as.factor(test$LS)
test$congruency <- as.factor(test$congruency)
test$mean <- as.numeric(test$mean)
View(test)
# Run four ANOVAs for the different components of interest
N1 <- subset(test, channel == "Pz" & window == "N1") # N1 in parietal region!
P2 <- subset(test, channel == "Fz" & window == "P2")
P3a <- subset(test, channel == "Fz" & window == "P3")
late_pos <- subset(test, channel == "Pz" & window == "P2/3")
# N1
df <- N1
# Summary statistics
summary <- df %>%
group_by(subject, agency, LS) %>%
get_summary_stats(mean, type = "mean")
# Run ANOVA
df <- ungroup(df) # Ungroup so that aov can work# Run AOV
aov <- anova_test(data = df, dv = mean, wid = subject, within = c(agency, congruency, LS))
# Get results
N1_aov <- get_anova_table(aov, correction = "none")
N1_summary <- summary
N1_summary
N1_aov
# P2
df <- P2
# Summary statistics
summary <- df %>%
group_by(subject, agency, LS) %>%
get_summary_stats(mean, type = "mean")
# Run ANOVA
df <- ungroup(df) # Ungroup so that aov can work# Run AOV
aov <- anova_test(data = df, dv = mean, wid = subject, within = c(agency, congruency, LS))
# Get results
P2_aov <- get_anova_table(aov, correction = "none")
P2_summary <- summary
P2_aov
# Extra t-test because it looks like there is something
PasCon <- subset(P2, agency == 0 & congruency == 1)
PasInc <- subset(P2, agency == 0 & congruency == 0)
PasCon <- PasCon %>%
group_by(subject) %>%
get_summary_stats(mean, type = "mean")
PasInc <- PasInc %>%
group_by(subject) %>%
get_summary_stats(mean, type = "mean")
t.test(PasCon$mean, PasInc$mean, paired = TRUE)
# P3a
df <- P3a
# Summary statistics
summary <- df %>%
group_by(subject, agency, LS) %>%
get_summary_stats(mean, type = "mean")
# Run ANOVA
df <- ungroup(df) # Ungroup so that aov can work# Run AOV
aov <- anova_test(data = df, dv = mean, wid = subject, within = c(agency, congruency, LS))
# Get results
P3a_aov <- get_anova_table(aov, correction = "none")
P3a_summary <- summary
P3a_aov
# Late positive component, parietal
df <- late_pos
# Summary statistics
summary <- df %>%
group_by(subject, agency, LS) %>%
get_summary_stats(mean, type = "mean")
# Run ANOVA
df <- ungroup(df) # Ungroup so that aov can work# Run AOV
aov <- anova_test(data = df, dv = mean, wid = subject, within = c(agency, congruency, LS))
# Late positive component, parietal
df <- late_pos
# Summary statistics
summary <- df %>%
group_by(subject, agency, LS) %>%
get_summary_stats(mean, type = "mean")
# Run ANOVA
df <- ungroup(df) # Ungroup so that aov can work# Run AOV
aov <- anova_test(data = df, dv = mean, wid = subject, within = c(agency, congruency, LS))
# Get results
late_pos_aov <- get_anova_table(aov, correction = "none")
late_pos_summary <- summary
late_pos_aov
# Load relevant packages
library(rstatix)
library(ggplot2)
# Load the data from logfiles
file_list <- list.files(path ="~/Uni/EyeSound/logfiles/")
file_list
# Merge the test files into one dataframe
for (file in file_list) {
# if the merged dataset doesn't exist, create it
if (!exists("dataset")) {
dataset <- read.csv2(file, header = TRUE, sep = "")
}
# if the merged dataset does exist, append to it
else if (exists("dataset")) {
temp_dataset <- read.csv2(file, header = TRUE, sep = "")
dataset <- rbind(dataset, temp_dataset)
rm(temp_dataset)
}
}
setwd("~/Uni/EyeSound/logfiles/")
# Load the data from logfiles
file_list <- list.files(path ="~/Uni/EyeSound/logfiles/")
# Merge the test files into one dataframe
for (file in file_list) {
# if the merged dataset doesn't exist, create it
if (!exists("dataset")) {
dataset <- read.csv2(file, header = TRUE, sep = "")
}
# if the merged dataset does exist, append to it
else if (exists("dataset")) {
temp_dataset <- read.csv2(file, header = TRUE, sep = "")
dataset <- rbind(dataset, temp_dataset)
rm(temp_dataset)
}
}
# Remove training trials (Contingency == 0)
dataset <- subset(dataset, dataset$Contingency != 0)
View(dataset)
# Check if response was correct by comparing answer and congruency columns
dataset[, "Correctness"] <-
NA # Add a column for evaluation of responses
is.nan.data.frame <- function(x)
do.call(cbind, lapply(x, is.nan))
dataset[is.nan(dataset)] <- NA
for (i in 1:nrow(dataset)) {
dataset[i, "Correctness"] <-
dataset[i, "Congruency"] == dataset[i, "Response"]
}
acquisition_trials <- subset(dataset, EventType == 2)
test_trials <- subset(dataset, EventType == 4)
test_trials[, "SoundKnown"] <- NA # Add a column to be filled later
# Drop unnecessary information from data frames
columns_acquisition <- c("Subject", "Contingency", "Block", "SoundID")
acquisition_trials <- acquisition_trials[columns_acquisition]
columns_test <- c("Subject", "Contingency", "Block", "Condition", "SoundID", "Correctness", "SoundKnown")
test_trials <- test_trials[columns_test]
# Make an empty data frame that will later contain the information we want
enriched_test_trials <- data.frame()
for(iSub in 2:26) {
for(iCon in 1:14) {
for(iBlock in 1:7) {
# Get the sounds that were played in preceeding acquisition trials
sounds_played <- subset(acquisition_trials, Subject == iSub & Contingency == iCon & Block <= iBlock)
# Get the sounds that were tested
tests <- subset(test_trials, Subject == iSub & Contingency == iCon & Block == iBlock)
# Add a "true" or "false" depending on whether the sound was played before
for(i in 1:nrow(tests)) {
tests[i, "SoundKnown"] <- tests[i,"SoundID"] %in% sounds_played$SoundID
}
# Append all temporary data sets
enriched_test_trials <- rbind(enriched_test_trials, tests)
}
}
}
# Clean up a little
rm(tests, acquisition_trials, test_trials, dataset, sounds_played, enriched_test_trials)
# Now that this is done, we want to drop the test trials that presented an unknown sound and plot the pruned data for each subject.
test_trials_valid <- subset(enriched_test_trials, SoundKnown == TRUE)
# Keep only columns of interest
remaining <- c("Subject", "Contingency", "Block", "Condition", "SoundID", "Correctness")
test_trials_valid <- test_trials_valid[remaining]
# Write the new data set as a .csv file
write.csv2(test_trials_valid, "D:/EyeSound/EyeSound_results_clean.csv")
enriched_test_trials
# Remove training trials (Contingency == 0)
dataset <- subset(dataset, dataset$Contingency != 0)
# Load relevant packages
library(rstatix)
library(ggplot2)
setwd("~/Uni/EyeSound/logfiles/")
# Load the data from logfiles
file_list <- list.files(path ="~/Uni/EyeSound/logfiles/")
# Merge the test files into one dataframe
for (file in file_list) {
# if the merged dataset doesn't exist, create it
if (!exists("dataset")) {
dataset <- read.csv2(file, header = TRUE, sep = "")
}
# if the merged dataset does exist, append to it
else if (exists("dataset")) {
temp_dataset <- read.csv2(file, header = TRUE, sep = "")
dataset <- rbind(dataset, temp_dataset)
rm(temp_dataset)
}
}
View(dataset)
# Remove training trials (Contingency == 0)
dataset <- subset(dataset, dataset$Contingency != 0)
# Check if response was correct by comparing answer and congruency columns
dataset[, "Correctness"] <-
NA # Add a column for evaluation of responses
is.nan.data.frame <- function(x)
do.call(cbind, lapply(x, is.nan))
dataset[is.nan(dataset)] <- NA
for (i in 1:nrow(dataset)) {
dataset[i, "Correctness"] <-
dataset[i, "Congruency"] == dataset[i, "Response"]
}
View(dataset)
acquisition_trials <- subset(dataset, EventType == 2)
test_trials <- subset(dataset, EventType == 4)
test_trials[, "SoundKnown"] <- NA # Add a column to be filled later
# Drop unnecessary information from data frames
columns_acquisition <- c("Subject", "Contingency", "Block", "SoundID")
acquisition_trials <- acquisition_trials[columns_acquisition]
columns_test <- c("Subject", "Contingency", "Block", "Condition", "SoundID", "Correctness", "SoundKnown")
test_trials <- test_trials[columns_test]
View(test_trials)
# Make an empty data frame that will later contain the information we want
enriched_test_trials <- data.frame()
for(iSub in 2:26) {
for(iCon in 1:14) {
for(iBlock in 1:7) {
# Get the sounds that were played in preceeding acquisition trials
sounds_played <- subset(acquisition_trials, Subject == iSub & Contingency == iCon & Block <= iBlock)
# Get the sounds that were tested
tests <- subset(test_trials, Subject == iSub & Contingency == iCon & Block == iBlock)
# Add a "true" or "false" depending on whether the sound was played before
for(i in 1:nrow(tests)) {
tests[i, "SoundKnown"] <- tests[i,"SoundID"] %in% sounds_played$SoundID
}
# Append all temporary data sets
enriched_test_trials <- rbind(enriched_test_trials, tests)
}
}
}
# Clean up a little
rm(tests, acquisition_trials, test_trials, dataset, sounds_played, enriched_test_trials)
# Make an empty data frame that will later contain the information we want
enriched_test_trials <- data.frame()
for(iSub in 2:26) {
for(iCon in 1:14) {
for(iBlock in 1:7) {
# Get the sounds that were played in preceeding acquisition trials
sounds_played <- subset(acquisition_trials, Subject == iSub & Contingency == iCon & Block <= iBlock)
# Get the sounds that were tested
tests <- subset(test_trials, Subject == iSub & Contingency == iCon & Block == iBlock)
# Add a "true" or "false" depending on whether the sound was played before
for(i in 1:nrow(tests)) {
tests[i, "SoundKnown"] <- tests[i,"SoundID"] %in% sounds_played$SoundID
}
# Append all temporary data sets
enriched_test_trials <- rbind(enriched_test_trials, tests)
}
}
}
library(rstatix)
library(ggplot2)
setwd("~/Uni/EyeSound/logfiles/")
# Load the data from logfiles
file_list <- list.files(path ="~/Uni/EyeSound/logfiles/")
# Merge the test files into one dataframe
for (file in file_list) {
# if the merged dataset doesn't exist, create it
if (!exists("dataset")) {
dataset <- read.csv2(file, header = TRUE, sep = "")
}
# if the merged dataset does exist, append to it
else if (exists("dataset")) {
temp_dataset <- read.csv2(file, header = TRUE, sep = "")
dataset <- rbind(dataset, temp_dataset)
rm(temp_dataset)
}
}
# Remove training trials (Contingency == 0)
dataset <- subset(dataset, dataset$Contingency != 0)
# Check if response was correct by comparing answer and congruency columns
dataset[, "Correctness"] <-
NA # Add a column for evaluation of responses
is.nan.data.frame <- function(x)
do.call(cbind, lapply(x, is.nan))
dataset[is.nan(dataset)] <- NA
for (i in 1:nrow(dataset)) {
dataset[i, "Correctness"] <-
dataset[i, "Congruency"] == dataset[i, "Response"]
}
# Exclude test trials that test sounds that are at this stage unknown
# Make another column that contains a boolean value which is positive when the
# sound presented in a test trial has been played in the preceeding acquisition
# trials.
# The following code checks if any given test sound was presented in any of the
# preceeding acquisition trials
acquisition_trials <- subset(dataset, EventType == 2)
test_trials <- subset(dataset, EventType == 4)
test_trials[, "SoundKnown"] <- NA # Add a column to be filled later
# Drop unnecessary information from data frames
columns_acquisition <- c("Subject", "Contingency", "Block", "SoundID")
acquisition_trials <- acquisition_trials[columns_acquisition]
columns_test <- c("Subject", "Contingency", "Block", "Condition", "SoundID", "Correctness", "SoundKnown")
test_trials <- test_trials[columns_test]
# Make an empty data frame that will later contain the information we want
enriched_test_trials <- data.frame()
for(iSub in 2:26) {
for(iCon in 1:14) {
for(iBlock in 1:7) {
# Get the sounds that were played in preceeding acquisition trials
sounds_played <- subset(acquisition_trials, Subject == iSub & Contingency == iCon & Block <= iBlock)
# Get the sounds that were tested
tests <- subset(test_trials, Subject == iSub & Contingency == iCon & Block == iBlock)
# Add a "true" or "false" depending on whether the sound was played before
for(i in 1:nrow(tests)) {
tests[i, "SoundKnown"] <- tests[i,"SoundID"] %in% sounds_played$SoundID
}
# Append all temporary data sets
enriched_test_trials <- rbind(enriched_test_trials, tests)
}
}
}
# Clean up a little
rm(tests, acquisition_trials, test_trials, dataset, sounds_played)
# Now that this is done, we want to drop the test trials that presented an unknown sound and plot the pruned data for each subject.
test_trials_valid <- subset(enriched_test_trials, SoundKnown == TRUE)
# Keep only columns of interest
remaining <- c("Subject", "Contingency", "Block", "Condition", "SoundID", "Correctness")
test_trials_valid <- test_trials_valid[remaining]
# Write the new data set as a .csv file
write.csv2(test_trials_valid, "results_clean.csv")
# Uncomment if you want to start here
# test_trials_valid <- read.csv("D:/EyeSound/EyeSound_results_clean.csv", sep=";")
remaining <- c("Subject", "Contingency", "Block", "Condition", "SoundID", "Correctness")
test_trials_valid <- test_trials_valid[remaining]
# Initialize an empty data frame
subjects <- data.frame(matrix(ncol = 2, nrow = 0))
names <- c("Subject", "PercentCorrect")
colnames(subjects) <- names
# Calculate the %Correct for each subject overall
for(iSub in 2:26) {
# Subset responses for subject
data = subset(test_trials_valid, test_trials_valid$Subject == iSub)
data <- group_by(data, Subject)
data <- summarise(data, PercentCorrect = length(which(data$Correctness==TRUE)) / length(data$Correctness))
subjects <- rbind(subjects, data)
}
rm(data)
# Plot the subjects' performance
ggplot(subjects, aes(x=Subject, y=PercentCorrect)) +
geom_text(label=as.character(subjects$Subject))+
geom_hline(yintercept=0.5, linetype="dashed", color = "red") +
theme_bw() +
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank())
